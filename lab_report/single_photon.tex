\documentclass[main.tex]{subfiles}
\begin{document}

\section{Indivisibility of the photon}

\subsection{Background}

The fact that light is made up of indivisible photons is not the only possible explanation for the photoelectric effect \cite[]{thornObservingQuantumBehavior2004}: it can also be described with a quantized surface and a classical electromagnetic field. 

So, we need an experiment to unambiguously show that light is indeed made up of indivisible \emph{quanta}.

\subsection{Experimental setup}

\begin{figure}[ht]
\centering
\input{figures/spdc.tex}
\caption{Indivisibility experiment setup.}
\label{fig:spdc}
\end{figure}

A schematic for the apparatus is provided in figure \ref{fig:spdc}. 
A LASER produces a coherent beam of light, whose photons have energy \(2 \hbar \omega  \). This beam impacts upon a nonlinear crystal, where a photon each \(\num{e6} \divisionsymbol \num{e8}\) undergoes Spontaneous Parametric Down-Conversion, being split into two entangled photons, each with energy \(\hbar \omega \). 
These are emitted in two cones which intersect along two rays. 

Along one of these the photon is sent to a detector called ``Gate'', along the other the photon is sent towards a beamsplitter; from this it can go to either of two detectors, which are called ``T'' and ``R'' for ``Transmitted'' and ``Reflected''.

Each detector has a nonzero ``dark count'' --- clicks in the absence of a photon ---, and an efficiency different from \SI{100}{\percent}. Also, photons might be absorbed by the air in their path or by the beamsplitter.

Let us first consider the problem ideally, in the absence of these sources of error.
Then, a click in the ``Gate'' detector signals that a photon is also coming through the beamsplitter. 

Then, according to quantum theory if that photon is reflected it is not transmitted, and vice versa. 
If, instead, we describe the electromagnetic field classically we expect the detection probability per unit time for both ``R'' and ``T'' to be proportional to the incoming power, with no correlation nor anticorrelation between them. 

We may quantify this by introducing the second order time coherence parameter 
%
\begin{align}
g^{(2)} (0) = \frac{ \mathbb{P} (RT | G) }{\mathbb{P}(R|G) \mathbb{P}(T|G)}
\,,
\end{align}
%
where by \(RT | G\) we mean the event of observing a R+T coincidence, conditioned upon seeing a click by the gate; the notation for the other ones is similar. We will omit the argument \((0)\) hereafter; different values for it would indicate measurement of correlations at different times. 

This can be computed by counting the number of coincidences, the expression is 
%
\begin{align}
g^{(2)}_{\text{measured}} = \frac{N_{TRG} N_G}{N_{RG} N_{TG}}
\,.
\end{align}

This parameter allows us to quantify the correlation or anticorrelation between the detectors: let us consider some simple cases. 

\begin{enumerate}
    \item In quantum theory, we expect \(\mathbb{P}(RT|G) = 0\), since the photon cannot be detected at both sides --- therefore \(g^{(2)} = 0\).
    \item In classical theory, we expect \(\mathbb{P}(RT|G) = \mathbb{P}(R|G) \mathbb{P}(T|G)\), since the events are independent, at each moment in time. If the laser's intensity is constant this can be extrapolated through the whole observation to yield \(g^{(2)} = 1\). 
    \item In classical theory we can also consider the effect of a time-varying intensity. In that case, this intensity \(I(t)\) is split into \(\mathcal{T}I(t)\) and \(\mathcal{R}I(t)\) at the detector, where \(\mathcal{T}\) and \(\mathcal{R}\) are the transmission and reflection coefficients, satisfying \(\mathcal{T} + \mathcal{R} =1\). Then, we get 
    %
    \begin{align}
    g^{(2)} = \frac{ \int \mathcal{T} I(t) \mathcal{R}I(t) \dd{t}}{ \int \mathcal{T} I(t) \dd{t} \int \mathcal{R} I(t) \dd{t}} \geq 1
    \,,
    \end{align}
    %
    by the Cauchy-Schwarz inequality. All the temporal integrals are definite ones, the bounds corresponding to the time of observation. For a small enough temporal variation of the intensity, the result approaches 1. 
\end{enumerate}

This is all in the case of an ideal detector, with no losses nor dark count. We do not explore the effect of these theoretically; instead in the data analysis these effects are parametrized and simulated as stochastic variables. 

\subsection{Data preparation}

The output of the timetagger is a table of times and corresponding channel values.
Each entry of this table represents a photon detection at a single detector.
The times are expressed as integer multiples of the temporal resolution of the timetagger, which is nominally \SI{80.955}{ps}.

There is a slight complication: the timetagger exhibits a slight preference for odd values of the integer which represents the time, as opposed to even ones. This effect does not pose an issue for our analysis, as long as we bin our arrival times in time intervals of \(2 \times \SI{80.955}{ps}\). 

We want to calculate \textbf{coincidences}. The temporal resolution we have corresponds to a length scale of around \SI{5}{cm}, which is smaller than the size of the apparatus, so we are able to see systematic time differences between the arrival times corresponding to the light's travel time. 

In figure \ref{fig:single_photon_timedifferences} we plot the differences between the arrival times of photons to either R or T and the gate. 

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/single_photon_timedifferences}
\caption{Time differences. In a darker colour the events which were counted as coincidences are shown.}
\label{fig:single_photon_timedifferences}
\end{figure}

We see distinct Gaussian peaks a few nanoseconds away from zero. We fit these, and find the means to be 10 and 27 respectively, while the standard deviations are both 3.

Outside of these peaks, there is a constant noise background of the order of 10 detections per \(\Delta t\) bin.
We choose to consider as coincidences events which lie within 5 standard deviations in each peak, since around that point the values become compatible with those of the background.

This allows us to compute \(N_{RG}\) and \(N_{TG}\); \(N_G\) is simply the total count of the gate; for \(N_{TRG}\) we count a coincidence if we have a coincidence on both R and T corresponding to the \emph{same} gate tick. 

This procedure yields \(N_G = 1554341\), \(N_{TG}=14829\), \(N_{RG}=13870\), \(N_{TRG}=2\).
Therefore, we compute the preliminary result:
%
\begin{align}
g^{(2)} \approx \num{.015}
\,.
\end{align}

\subsection{Simulation}

In order to perform a proper Bayesian analysis of these results, we need to compute the Bayes Factor in: 
%
\begin{align}
\frac{\mathbb{P}(\text{quantum} | \text{data})}{\mathbb{P}(\text{classical} | \text{data})}
= \underbrace{\frac{\mathbb{P}(\text{data} | \text{quantum})}{\mathbb{P}(\text{data} | \text{classical})}}_{\text{Bayes Factor}}
\frac{\mathbb{P}(\text{quantum})}{\mathbb{P}(\text{classical})}
\,.
\end{align}

Some clarifications are in order. By ``data'' we mean the tuple \((N_G, N_{TG}, N_{RG}, N_{TRG})\). I use the notation \(\mathbb{P}\) for ease of reading, but the Bayes Factor is really a ratio of two probability \emph{densities}.\footnote{Or rather, since the detection numbers are so large, it is convenient to model them as continuous.}
The two models --- quantum and classical --- are simulated and an estimate for the \(BF\) is calculated as follows.

\begin{enumerate}
    \item The number \(N_G\) is fixed as the total number of potential event detections for either detector. 
    \item We set two parameters: \(r\), the detection rate, and \(e\), the error rate.
    Each detector is assumed to detect a fraction \(r\) of the incoming photons, and to make an error a fraction \(e\) of the time --- this can be either a dark count, or a missed detection (although since \(r \ll 1\), it mostly accounts for the former).\footnote{A small correction is needed to account for the detector asymmetry. We observe \(N_{TG} - N_{RG} \approx 1000\), which is on the order of \(8 \sigma \) using Poisson statistics (\(\sqrt{N_{TG}} \approx 122\)): so, there is a bias in the detectors or in the beamsplitter --- we cannot tell, but surely it is the case that statistically more coincidences are detected in one detector than the other. This is accounted for by calculating the factor \(b = N_{TG} / N_{RG}\) from the data and applying it as a \emph{constant bias} for each simulated ratio between the detectors, for both models. So, if one detector is simulated to have a rate \(r\) the other one is simulated to have a detection rate \(br\).}
    \item In the classical case, the detectors are simulated independently, while in the quantum case a ``which-way'' parameter is simulated with a \(1/2\) chance for either direction, and only the selected detector may see the photon. In order to account for the halving of the number of photons seen globally (and to compare the numbers for the classical and quantum case directly), the detection rate for the classical is halved.
    \item The computation for \(\mathbb{P}(\text{data} | M)\) where \(M\) is a model is as follows: 
    %
    \begin{align}
    \mathbb{P}(\text{data} | M) = 
    \int \mathbb{P}(\text{data} | M; r, e) f(r) f(e) \dd{r} \dd{e}
    \,,
    \end{align}
    %
    where \(f(r)\) and \(f(e)\) are the prior probability distributions for the detection rate and the error rate. 
    Both of these were chosen to be uniform, and their ranges were not constrained \emph{a priori} to be smaller than \([0,1]\); however after exploratory runs it was found that the likelihoods for both models were nonzero only in a certain region, so only those were simulated for computational efficiency.
    
    The definitive intervals were \(r \in [\num{.012}, \num{0.019}]\) and \(e \in [\num{3.0e-7}, \num{1.8e-2}]\); 50 points were simulated for each, they were linearly spaced for \(r\) and logarithmically spaced for \(e\). 
    \item For each pair of parameters, \(N_G\) photons were simulated for \(N _{\text{sim}}\) times. In the final run, we set \(N _{\text{sim}}\) to 600. 
    
    For each of the \(N _{\text{sim}}\) simulations the values \(N_{TG}\), \(N_{RG}\) and \(N_{TRG}\) are extracted (also, trivially, the fixed value of \(N_G\)). 
    From these, a gaussian Kernel-Density Estimation technique (using Scott's rule \cite[]{scipycontributorsScipyStatsGaussian2019,scottMultivariateDensityEstimation2015}) is used to estimate the value of the multivariate PDF at the point corresponding to the measured data for both models: the likelihood of the data.
    The variation of these likelihoods is shown in figure \ref{fig:both_logpdfs}. 
    \item These likelihoods are integrated along \(r\) and \(e\) to yield a total value. We find 
    %
    \begin{align}
    BF = \frac{\mathbb{P}(\text{data} | \text{quantum})}{\mathbb{P}(\text{data} | \text{classical})}
    \approx \num{e77}
    \,.
    \end{align}
\end{enumerate}

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/both_logpdfs}
\caption{Log-PDFs for the classical and quantum cases. Note the log-scale of the colours: the likelihood of the classical model is \emph{heavily} suppressed compared to the one of the quantum model.}
\label{fig:both_logpdfs}
\end{figure}

The code which performs these simulations can be found at \url{https://github.com/jacopok/quantum_optics/tree/master/single_photon}. 

A note on the parametrization: we use only two parameters for our model because it is the least amount which can reproduce the experimental results.
This is certainly a heavy simplifying assumption: we are considering each gate click as ``guaranteed'', and putting all the uncertainty in the other two detectors.
This may seem like an issue, but it is not. The effect of errors (dark count and missed photons) in the gate and in the detectors is always a bit-flip in the end, so we can parametrize away our ignorance of the precise cause of a certain error. 

Since we have to marginalize over any new parameter we introduce, we are forced to have a small number of them to have a computationally tractable problem. 

\end{document}
